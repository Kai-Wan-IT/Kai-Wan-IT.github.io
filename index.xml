<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Kai Wan&#39;s Page</title>
    <link>http://Kai-Wan-IT.github.io/</link>
    <description>Recent content in Home on Kai Wan&#39;s Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Sep 2018 00:00:00 +0000</lastBuildDate><atom:link href="http://Kai-Wan-IT.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>EUSIPCO&#39;18 tutorial</title>
      <link>http://Kai-Wan-IT.github.io/posts/eusipco18/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/posts/eusipco18/</guid>
      <description>I will be giving a tutorial at the 26th European Signal Processing Conference (EUSIPCO&#39;18) in Rome, the Eternal City, Italy, together with my Ph.D. supervisor Prof. Romain Couillet and my colleague Xiaoyi Mai on the topic of &amp;ldquo;Random Matrix Advances in Machine Learning and Neural Nets&amp;rdquo;.
For more information please visit EUSIPCO&#39;18.
Abstract
The advent of the Big Data era has triggered a renewed interest for machine learning and (deep) neural networks.</description>
    </item>
    
    <item>
      <title>EUSIPCO&#39;18 tutorial</title>
      <link>http://Kai-Wan-IT.github.io/posts/gretsi17/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/posts/gretsi17/</guid>
      <description>I will be presenting our work about Random Feature Maps at Colloque GRETSI&#39;17 this September at Juan Les Pins, France. The slides (in French) are available here.</description>
    </item>
    
    <item>
      <title>EUSIPCO&#39;18 tutorial</title>
      <link>http://Kai-Wan-IT.github.io/posts/icassp17/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/posts/icassp17/</guid>
      <description>I will be presenting my work on LS-SVM at the 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017), New Orleans, USA.
Here is the link to this four-paper conference paper. A extended journal version which contains all proof in detail is available here.
The slides presented on ICASSP 2017 are available here.</description>
    </item>
    
    <item>
      <title>EUSIPCO&#39;18 tutorial</title>
      <link>http://Kai-Wan-IT.github.io/posts/icassp19/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/posts/icassp19/</guid>
      <description>My colleague Xiaoyi Mai will be presenting our paper on high dimensional logistic regression at ICASSP&#39;19, 12-17 May, Brighton, UK.
The slides are available here.</description>
    </item>
    
    <item>
      <title>EUSIPCO&#39;18 tutorial</title>
      <link>http://Kai-Wan-IT.github.io/posts/icml18/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/posts/icml18/</guid>
      <description>I will be presenting our works on Random Feature-based Clustering as well as Gradient Descent Dynamics at ICML 2018 this July, please find the two papers as follows:
[On the Spectrum of Random Features Maps of High Dimensional Data] and the slides here [The Dynamics of Learning: A Random Matrix Approach] and the slides here. </description>
    </item>
    
    <item>
      <title>Ph.D. Mid-term</title>
      <link>http://Kai-Wan-IT.github.io/posts/phd_mid/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/posts/phd_mid/</guid>
      <description>I&amp;rsquo;ve just finished my Ph.D. mid-term evaluation at CentraleSupelec. Here is the link of my mid-term report as well the slides.</description>
    </item>
    
    <item>
      <title>Activities</title>
      <link>http://Kai-Wan-IT.github.io/activities/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/activities/</guid>
      <description>Talks Invited talk on &amp;ldquo;A Data-dependent Theory of Overparameterization: Phase Transition, Double Descent, and Beyond&amp;rdquo; at Workshop on the Theory of Over-parameterized Machine Learning (TOPML) 2021, April 20-21, 2021. See slides, two-page abstract, and paper. Invited talk on &amp;ldquo;Performance-complexity Trade-off in Large Dimensional Spectral Clustering&amp;rdquo; at Statistics Seminar, Research School of Finance, Actuarial Studies and Statistics, Australian National University, Canberra, March 4, 2021. See slides here. Invited talk on &amp;ldquo;Performance-complexity Trade-off in Large Dimensional Spectral Clustering&amp;rdquo;, STA 290 Seminar, Department of Statistics, University of California, Davis, January 21, 2021.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>http://Kai-Wan-IT.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/publications/</guid>
      <description>Journals: Kai Wan*, Hua Sun, Mingyue Ji, and Giuseppe Caire, “On Secure Distributed Linearly Separable Computation”, IEEE Journal on Selected Areas in Communications (IEEE JSAC), vol. 40, no. 3, pp. 912-926, Mar. 2022.
Kai Wan*, Hua Sun, Mingyue Ji, Daniela Tuninetti, and Giuseppe Caire, “Cache-Aided Matrix Multiplication Retrieval”, IEEE Trans. on Information Theory (IEEE TIT), vol. 68, no. 7, pp. 4301-4319, July 2022.
Kai Wan*, Hua Sun, Mingyue Ji, Daniela Tuninetti, and Giuseppe Caire, “On the Fundamental Limits of Device-to-Device Private Caching under Uncoded Cache Placement and User Collusion”, IEEE Trans.</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>http://Kai-Wan-IT.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://Kai-Wan-IT.github.io/teaching/</guid>
      <description>Teaching I am teaching &amp;ldquo;Deep Learning and Computer Vision&amp;rdquo; in the 2021 Fall semester, together with Prof. Xinggang Wang (https://xinggangw.info), below are the assignments/mini-projects aiming to improve your theoretical understanding and practical (coding) skills.
mini-project 1: training a linear model with gradient descent, see description here mini-project 2: training a single-hidden-layer neural network model, see description here mini-project 3: training a convolutional neural network, see description here mini-project 4: build your own MNIST-GAN, see description here </description>
    </item>
    
  </channel>
</rss>
